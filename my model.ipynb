{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load various imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(filename):\n",
    "    audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\91844\\\\Desktop\\\\Important\\\\sound classification project\\\\FanDataset\\\\NormalFanNoise\\\\'\n",
    "\n",
    "extracted_features=[]\n",
    "for file in os.listdir(path):\n",
    "    class_label='NormalFan'\n",
    "    data=features_extractor(path+file)\n",
    "    extracted_features.append([data,class_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-184.08725, 190.90364, -6.5472474, 69.83528, ...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-188.95596, 184.57324, -5.796834, 69.49344, -...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-187.72867, 227.37573, 1.7841598, 35.303238, ...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-205.62836, 199.65625, 16.706049, 50.15475, -...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-172.0737, 230.81796, -3.084025, 36.8795, -16...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature      class\n",
       "0  [-184.08725, 190.90364, -6.5472474, 69.83528, ...  NormalFan\n",
       "1  [-188.95596, 184.57324, -5.796834, 69.49344, -...  NormalFan\n",
       "2  [-187.72867, 227.37573, 1.7841598, 35.303238, ...  NormalFan\n",
       "3  [-205.62836, 199.65625, 16.706049, 50.15475, -...  NormalFan\n",
       "4  [-172.0737, 230.81796, -3.084025, 36.8795, -16...  NormalFan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"NormalFan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\91844\\\\Desktop\\\\Important\\\\sound classification project\\\\FanDataset\\\\faultyfan\\\\'\n",
    "\n",
    "extracted_features=[]\n",
    "for file in os.listdir(path):\n",
    "    class_label='FaultyFan'\n",
    "    data=features_extractor(path+file)\n",
    "    extracted_features.append([data,class_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-93.358574, 143.08846, -24.687855, 87.64721, ...</td>\n",
       "      <td>FaultyFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-83.99258, 133.55707, -43.555065, 84.07892, -...</td>\n",
       "      <td>FaultyFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-85.85156, 138.25967, -18.470726, 90.875084, ...</td>\n",
       "      <td>FaultyFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-84.16158, 128.17197, -36.546913, 96.57094, -...</td>\n",
       "      <td>FaultyFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-103.80153, 147.52713, -20.799234, 86.50566, ...</td>\n",
       "      <td>FaultyFan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature      class\n",
       "0  [-93.358574, 143.08846, -24.687855, 87.64721, ...  FaultyFan\n",
       "1  [-83.99258, 133.55707, -43.555065, 84.07892, -...  FaultyFan\n",
       "2  [-85.85156, 138.25967, -18.470726, 90.875084, ...  FaultyFan\n",
       "3  [-84.16158, 128.17197, -36.546913, 96.57094, -...  FaultyFan\n",
       "4  [-103.80153, 147.52713, -20.799234, 86.50566, ...  FaultyFan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"FaultyFan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\91844\\\\Desktop\\\\Important\\\\sound classification project\\\\FanDataset\\\\WeightedbladesNoise\\\\'\n",
    "\n",
    "extracted_features=[]\n",
    "for file in os.listdir(path):\n",
    "    class_label='WeightedbladesNoise'\n",
    "    data=features_extractor(path+file)\n",
    "    extracted_features.append([data,class_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-172.05176, 178.07889, -2.7258942, 64.90754, ...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-131.54875, 141.76346, -46.163578, 86.30664, ...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-154.2827, 141.59094, -45.067036, 66.9208, -3...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-123.77388, 141.92772, -51.178802, 66.29541, ...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-74.84768, 150.31708, -69.574745, 72.87649, -...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature                class\n",
       "0  [-172.05176, 178.07889, -2.7258942, 64.90754, ...  WeightedbladesNoise\n",
       "1  [-131.54875, 141.76346, -46.163578, 86.30664, ...  WeightedbladesNoise\n",
       "2  [-154.2827, 141.59094, -45.067036, 66.9208, -3...  WeightedbladesNoise\n",
       "3  [-123.77388, 141.92772, -51.178802, 66.29541, ...  WeightedbladesNoise\n",
       "4  [-74.84768, 150.31708, -69.574745, 72.87649, -...  WeightedbladesNoise"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"WeightedbladesNoise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-184.08725, 190.90364, -6.5472474, 69.83528, ...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-188.95596, 184.57324, -5.796834, 69.49344, -...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-187.72867, 227.37573, 1.7841598, 35.303238, ...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-205.62836, 199.65625, 16.706049, 50.15475, -...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-172.0737, 230.81796, -3.084025, 36.8795, -16...</td>\n",
       "      <td>NormalFan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>[-83.35173, 143.92805, -77.120445, 73.46474, -...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>[-84.10093, 145.62115, -70.71969, 74.50148, -3...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>[-87.92287, 145.3846, -70.38933, 70.88521, -34...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>[-86.80471, 148.24329, -81.79567, 77.111336, -...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>[-89.72744, 143.64076, -72.58681, 73.30572, -3...</td>\n",
       "      <td>WeightedbladesNoise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature                class\n",
       "0    [-184.08725, 190.90364, -6.5472474, 69.83528, ...            NormalFan\n",
       "1    [-188.95596, 184.57324, -5.796834, 69.49344, -...            NormalFan\n",
       "2    [-187.72867, 227.37573, 1.7841598, 35.303238, ...            NormalFan\n",
       "3    [-205.62836, 199.65625, 16.706049, 50.15475, -...            NormalFan\n",
       "4    [-172.0737, 230.81796, -3.084025, 36.8795, -16...            NormalFan\n",
       "..                                                 ...                  ...\n",
       "256  [-83.35173, 143.92805, -77.120445, 73.46474, -...  WeightedbladesNoise\n",
       "257  [-84.10093, 145.62115, -70.71969, 74.50148, -3...  WeightedbladesNoise\n",
       "258  [-87.92287, 145.3846, -70.38933, 70.88521, -34...  WeightedbladesNoise\n",
       "259  [-86.80471, 148.24329, -81.79567, 77.111336, -...  WeightedbladesNoise\n",
       "260  [-89.72744, 143.64076, -72.58681, 73.30572, -3...  WeightedbladesNoise\n",
       "\n",
       "[261 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_data = pd.concat([df1,df2,df3],ignore_index=True)\n",
    "Final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data.to_csv(\"Final Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(Final_data['feature'].tolist())\n",
    "y=np.array(Final_data['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (182, 40)\n",
      "X_test shape:  (79, 40)\n",
      "y_train shape:  (182, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \",X_train.shape)\n",
    "print(\"X_test shape: \",X_test.shape)\n",
    "print(\"y_train shape: \",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels=y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 44,703\n",
      "Trainable params: 44,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 3s 449ms/step - loss: 22.4748 - accuracy: 0.4237 - val_loss: 5.8372 - val_accuracy: 0.4557\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.83715, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 18.8697 - accuracy: 0.3923 - val_loss: 2.8121 - val_accuracy: 0.5443\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.83715 to 2.81213, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 15.2281 - accuracy: 0.4279 - val_loss: 1.1763 - val_accuracy: 0.7089\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.81213 to 1.17632, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 14.0268 - accuracy: 0.4533 - val_loss: 0.7585 - val_accuracy: 0.7595\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.17632 to 0.75849, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 12.1459 - accuracy: 0.4251 - val_loss: 0.9557 - val_accuracy: 0.7468\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.75849\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 8.6853 - accuracy: 0.5116 - val_loss: 1.1489 - val_accuracy: 0.7089\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.75849\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.7195 - accuracy: 0.5801 - val_loss: 0.8946 - val_accuracy: 0.7215\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.75849\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 5.3468 - accuracy: 0.5904 - val_loss: 0.5981 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.75849 to 0.59806, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.9813 - accuracy: 0.5895 - val_loss: 0.4816 - val_accuracy: 0.7975\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.59806 to 0.48162, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.9879 - accuracy: 0.5850 - val_loss: 0.3395 - val_accuracy: 0.8354\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.48162 to 0.33947, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.0812 - accuracy: 0.5467 - val_loss: 0.2627 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33947 to 0.26270, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.5661 - accuracy: 0.6116 - val_loss: 0.1832 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26270 to 0.18320, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3.0735 - accuracy: 0.6376 - val_loss: 0.2223 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.18320\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3.1309 - accuracy: 0.6161 - val_loss: 0.3378 - val_accuracy: 0.8228\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.18320\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.2084 - accuracy: 0.6906 - val_loss: 0.3228 - val_accuracy: 0.8354\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18320\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3.0437 - accuracy: 0.6600 - val_loss: 0.2571 - val_accuracy: 0.8481\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18320\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2.3008 - accuracy: 0.7134 - val_loss: 0.1859 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.18320\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.1494 - accuracy: 0.6571 - val_loss: 0.1991 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18320\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 2.0425 - accuracy: 0.6478 - val_loss: 0.2029 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18320\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.6481 - accuracy: 0.6654 - val_loss: 0.2419 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18320\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.5973 - accuracy: 0.7432 - val_loss: 0.2497 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.18320\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.8803 - accuracy: 0.6566 - val_loss: 0.2240 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.18320\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4556 - accuracy: 0.7431 - val_loss: 0.2051 - val_accuracy: 0.8987\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.18320\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4925 - accuracy: 0.7183 - val_loss: 0.1925 - val_accuracy: 0.9114\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.18320\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.1185 - accuracy: 0.7201 - val_loss: 0.1726 - val_accuracy: 0.9367\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18320 to 0.17259, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8227 - accuracy: 0.7930 - val_loss: 0.1636 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17259 to 0.16356, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.4686 - accuracy: 0.6974 - val_loss: 0.1547 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.16356 to 0.15467, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.3172 - accuracy: 0.7369 - val_loss: 0.1540 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.15467 to 0.15399, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.4596 - accuracy: 0.7726 - val_loss: 0.1537 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15399 to 0.15374, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9841 - accuracy: 0.7695 - val_loss: 0.1426 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15374 to 0.14259, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.5012 - accuracy: 0.7683 - val_loss: 0.1429 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14259\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.1225 - accuracy: 0.7904 - val_loss: 0.1328 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.14259 to 0.13280, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7666 - accuracy: 0.7927 - val_loss: 0.1191 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.13280 to 0.11909, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.8670 - accuracy: 0.8165 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11909 to 0.11556, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.8070 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11556\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7653 - accuracy: 0.7688 - val_loss: 0.1233 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11556\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7952 - accuracy: 0.7398 - val_loss: 0.1196 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11556\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5949 - accuracy: 0.8539 - val_loss: 0.1203 - val_accuracy: 0.9873\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11556\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7957 - accuracy: 0.7998 - val_loss: 0.1110 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.11556 to 0.11103, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7775 - accuracy: 0.7664 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.11103 to 0.10329, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6334 - accuracy: 0.8163 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10329\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3681 - accuracy: 0.8553 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10329 to 0.10203, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6728 - accuracy: 0.7989 - val_loss: 0.0952 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.10203 to 0.09521, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7633 - accuracy: 0.8025 - val_loss: 0.0916 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.09521 to 0.09157, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4407 - accuracy: 0.8509 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.09157 to 0.08649, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3654 - accuracy: 0.9016 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08649 to 0.08365, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4300 - accuracy: 0.8629 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08365 to 0.08282, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5413 - accuracy: 0.8429 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.08282 to 0.08198, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4515 - accuracy: 0.8816 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.08198 to 0.08034, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5390 - accuracy: 0.8105 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08034 to 0.07878, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4153 - accuracy: 0.9040 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.07878 to 0.07800, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6387 - accuracy: 0.8283 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.07800 to 0.07634, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2017 - accuracy: 0.8978 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.07634 to 0.07307, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3085 - accuracy: 0.8974 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.07307 to 0.06845, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4025 - accuracy: 0.8823 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.06845 to 0.06085, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3683 - accuracy: 0.8768 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.06085 to 0.05697, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4402 - accuracy: 0.8563 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.05697 to 0.05525, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3594 - accuracy: 0.8693 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05525 to 0.05079, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3298 - accuracy: 0.8435 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.05079 to 0.04903, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3511 - accuracy: 0.9080 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.04903 to 0.04633, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3059 - accuracy: 0.8997 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04633 to 0.04378, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2843 - accuracy: 0.9237 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04378\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2676 - accuracy: 0.8896 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04378\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4300 - accuracy: 0.9181 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04378\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2379 - accuracy: 0.9018 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04378\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3362 - accuracy: 0.8876 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.04378 to 0.04374, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3441 - accuracy: 0.8772 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.04374 to 0.04118, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1286 - accuracy: 0.9470 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.04118 to 0.04006, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2661 - accuracy: 0.9071 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.04006 to 0.03874, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3440 - accuracy: 0.8726 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.03874 to 0.03783, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4468 - accuracy: 0.9016 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.03783 to 0.03722, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2565 - accuracy: 0.9000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.03722\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1419 - accuracy: 0.9475 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.03722\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3501 - accuracy: 0.8834 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.03722 to 0.03596, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1616 - accuracy: 0.9504 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.03596 to 0.03359, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1704 - accuracy: 0.9588 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.03359 to 0.03111, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2554 - accuracy: 0.9285 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.03111 to 0.02829, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2765 - accuracy: 0.9172 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.02829 to 0.02616, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2517 - accuracy: 0.9119 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02616\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2213 - accuracy: 0.9464 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.02616 to 0.02578, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2020 - accuracy: 0.9455 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02578\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1600 - accuracy: 0.9195 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02578\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1289 - accuracy: 0.9195 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.02578 to 0.02508, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2608 - accuracy: 0.9149 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.02508 to 0.02347, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1670 - accuracy: 0.9242 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.02347 to 0.02252, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2060 - accuracy: 0.9318 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.02252 to 0.02246, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1910 - accuracy: 0.9513 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.02246 to 0.02245, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2472 - accuracy: 0.9009 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.02245 to 0.02171, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1799 - accuracy: 0.9306 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.02171 to 0.02136, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1631 - accuracy: 0.9461 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.02136 to 0.02111, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2022 - accuracy: 0.9561 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.02111 to 0.02042, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1206 - accuracy: 0.9660 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.02042 to 0.02014, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2356 - accuracy: 0.9009 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.02014 to 0.01982, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1489 - accuracy: 0.9622 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.01982 to 0.01959, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1402 - accuracy: 0.9408 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.01959\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1511 - accuracy: 0.9580 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.01959 to 0.01908, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1789 - accuracy: 0.9501 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.01908 to 0.01857, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1361 - accuracy: 0.9403 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.01857 to 0.01735, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1082 - accuracy: 0.9772 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01735 to 0.01551, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1703 - accuracy: 0.9298 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.01551 to 0.01349, saving model to C:\\Users\\91844\\Desktop\\Important\\sound classification project\\Saved models\\audio_classification.hdf5\n",
      "Training completed in time:  0:00:12.735618\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='C:\\\\Users\\\\91844\\\\Desktop\\\\Important\\\\sound classification project\\\\Saved models\\\\audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 1, 0,\n",
       "       1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 0, 0, 2, 0, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1,\n",
       "       1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91844\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 2, 0, 2, 2, 1, 0,\n",
       "       1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 0, 0, 2, 0, 1,\n",
       "       1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1,\n",
       "       1, 0, 2, 1, 0, 0, 0, 0, 1, 2, 1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=model.predict_classes(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  0,  0],\n",
       "       [ 0, 36,  0],\n",
       "       [ 0,  0, 23]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0293791e+02  2.2071227e+02  1.5825939e+01  3.1833752e+01\n",
      "  2.3305397e+00  1.2287267e+01  8.0954771e+00 -2.9111354e+00\n",
      "  7.6514089e-01 -1.8769060e+00  4.0891919e+00 -3.6546390e+00\n",
      "  1.2687507e+00 -2.6300827e-01 -2.3938851e+00 -1.2563185e-01\n",
      " -2.0397182e+00  4.3917480e-01 -3.0210164e+00 -5.4063338e-01\n",
      " -1.1667554e+00 -2.0433290e+00 -2.0752246e+00 -2.7953534e+00\n",
      " -1.2671468e+00 -2.9746258e+00 -1.1783874e+00 -2.7860906e+00\n",
      " -1.5987916e+00 -1.8916085e+00 -2.7459683e+00 -8.2427406e-01\n",
      " -3.3708594e+00 -9.1791791e-01 -2.2013009e+00 -2.1560917e+00\n",
      " -1.1892284e+00 -2.8277683e+00 -8.8909358e-01 -2.8971841e+00]\n",
      "[[-2.0293791e+02  2.2071227e+02  1.5825939e+01  3.1833752e+01\n",
      "   2.3305397e+00  1.2287267e+01  8.0954771e+00 -2.9111354e+00\n",
      "   7.6514089e-01 -1.8769060e+00  4.0891919e+00 -3.6546390e+00\n",
      "   1.2687507e+00 -2.6300827e-01 -2.3938851e+00 -1.2563185e-01\n",
      "  -2.0397182e+00  4.3917480e-01 -3.0210164e+00 -5.4063338e-01\n",
      "  -1.1667554e+00 -2.0433290e+00 -2.0752246e+00 -2.7953534e+00\n",
      "  -1.2671468e+00 -2.9746258e+00 -1.1783874e+00 -2.7860906e+00\n",
      "  -1.5987916e+00 -1.8916085e+00 -2.7459683e+00 -8.2427406e-01\n",
      "  -3.3708594e+00 -9.1791791e-01 -2.2013009e+00 -2.1560917e+00\n",
      "  -1.1892284e+00 -2.8277683e+00 -8.8909358e-01 -2.8971841e+00]]\n",
      "(1, 40)\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NormalFan'], dtype='<U19')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"C:\\\\Users\\\\91844\\\\Desktop\\\\Important\\\\sound classification project\\\\NormalFan.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
